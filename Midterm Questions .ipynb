{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make your own 1/2 final exam. Write an exam in an ipython notebook that has\n",
    "\n",
    "* Submit 8 multiple choice concept questions\n",
    "* Submit 7 true-false choice\n",
    "* 5 Short-answer Data Camp-Style Notebook questions\n",
    "* Provide 1 Task on Data Set Mini\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Concept Multiple-Choice questions:\n",
    "--------------------------------\n",
    "\n",
    "Q1. Which of these is *not* a common option for filling in \"missing\" values\n",
    "- (a) using an impossible number like -9999\n",
    "- (b) using the standard deviation\n",
    "- (c) using 0\n",
    "- (d) using the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Which of these methods is best for grouping a datetime-indexed dataframe or series by a time frequency and performing aggregations over that frequency. \n",
    "\n",
    "* (a) resample.( ) <- correct answer\n",
    "* (b) asfreq.( )\n",
    "* (c) shift.( )\n",
    "* (d) to_period.( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. The process of converting an existing times-series to a higher time frequency--which requires filling or interpolating missing data of the new time-series--is known as:\n",
    "* (a) Downsampling\n",
    "* (b) Upsampling\n",
    "* (c) Resampling\n",
    "* (d) Oversampling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True-False Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) A set is a mutable data type \n",
    "    * True (correct) \n",
    "    * False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Short Answer Question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import what we need\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "plt.style.use('ggplot')\n",
    "mpl.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "#Part 1 \n",
    "# Generate a random walk of for stock prices\n",
    "# Stock prices are typically positive and increase\n",
    "# and decrease in terms of percent growth (returns)\n",
    "# We will create a random walk of returns\n",
    "# and turn that into prices\n",
    "# and then plot\n",
    "num_samples = 100\n",
    "sigma = 0.05\n",
    "mu = 0.01\n",
    "seed = 42\n",
    "# Part 1, seed the numpy random number generateor with the seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Part 2\n",
    "# create a sequence of num_samples in length picked\n",
    "# from a normal distrubution with mean mu and standerd deviation sigma\n",
    "deltas = np.random.randn(num_samples)*sigma + mu\n",
    "\n",
    "# Part 3\n",
    "# create log_return series as a random walk \n",
    "# of the deltas starting at 0 where\n",
    "# each of the deltas is our next step\n",
    "log_returns = deltas.cumsum()\n",
    "\n",
    "# Part 3\n",
    "# create log_return series as a random walk \n",
    "# of the deltas starting at 0 where\n",
    "# each of the deltas is our next step\n",
    "log_returns = deltas.cumsum()\n",
    "\n",
    "# Part 4\n",
    "# We exponentiate (raise \"10\" to the power of\n",
    "# log_returns) our log_returns to create returns\n",
    "# and use them to discount the starting price to get our\n",
    "# prices\n",
    "start = 100\n",
    "prices = start*(10**(log_returns))\n",
    "\n",
    "#Part 5\n",
    "# Lets greate a pandas sequence of dates\n",
    "# from jan 2, 2025 on business days\n",
    "# for each of our prices\n",
    "dates = pd.date_range(start='2025-1-2',periods=len(prices),freq='B')\n",
    "\n",
    "#Part 6\n",
    "# lets make a pandas data frame with 'date' column and a column\n",
    "# of 'price' (by makeing a dictionary)\n",
    "\n",
    "df = pd.DataFrame({'date':dates, 'price':prices})\n",
    "\n",
    "#Part 7\n",
    "#set the index to the 'date' column\n",
    "df.set_index(['date'])\n",
    "\n",
    "#Part 8\n",
    "# print the first 10 columns\n",
    "df.head()\n",
    "\n",
    "#part 9\n",
    "#use the build in lineplot within pandas\n",
    "# to plot the date vs the price\n",
    "_ = df.plot.line(x='date',y='price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datacamp short exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Time-series exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1: import pandas, numpy and matplotlib.pyplot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.style.use('ggplot')\n",
    "%matplotlib inline \n",
    "\n",
    "#Part 2: read and store dataset as pandas dataframe. inspect the number values associated with columns.\n",
    "\n",
    "\n",
    "#part 3: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) importing data from web with request "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Looking at the distribution of average SAT scores by nyc high school."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 478 entries, 0 to 477\n",
      "Data columns (total 6 columns):\n",
      "dbn                               478 non-null object\n",
      "num_of_sat_test_takers            478 non-null object\n",
      "sat_critical_reading_avg_score    478 non-null object\n",
      "sat_math_avg_score                478 non-null object\n",
      "sat_writing_avg_score             478 non-null object\n",
      "school_name                       478 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 22.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#part 1 - read in 2012 avg sat scores by nyc schools; data retrieved from nyc open data. Print info and first five rows.\n",
    "csvfile='https://data.cityofnewyork.us/resource/734v-jeq5.csv'\n",
    "df = pd.read_csv(csvfile)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dtype' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-16be5e3c501d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#see number of test takers by school\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_of_sat_test_takers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dtype' is not defined"
     ]
    }
   ],
   "source": [
    "#see number of test takers by school\n",
    "df.num_of_sat_test_takers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Webscraping data table from wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
